{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lOmarMisbahl/PatternRecognition-Sheets/blob/main/Assignment4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3wTX8UN8R0L"
      },
      "source": [
        "from os import listdir\n",
        "from PIL import Image as PImage\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q1xmNQcf1XG"
      },
      "source": [
        "def loadImages(path):\n",
        "    foldersList = listdir(path)\n",
        "    loadedImages = []\n",
        "    for folder in foldersList :\n",
        "        imagesList = listdir(path+folder)\n",
        "        for image in imagesList:\n",
        "            img = PImage.open(path +folder+'/'+ image)\n",
        "            loadedImages.append(img)\n",
        "    return loadedImages"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORLaXe2e_cS1",
        "outputId": "a55d1db1-1999-4b22-edef-8716f041649c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HosTGfj-vHE"
      },
      "source": [
        "path = \"/content/drive/MyDrive/ORL/\"\n",
        "imgs = loadImages(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2YTsnETKgPf"
      },
      "source": [
        "dataMatrix = np.arange(400*5600).reshape(400,5600)\n",
        "j=0\n",
        "label = []\n",
        "for i in range(0,400) :\n",
        "    if(i%10 == 0):\n",
        "        j+=1\n",
        "    dataMatrix[i] = np.array(imgs[i]).flatten()\n",
        "    label.append(j)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8sv_fk4Oz9Z"
      },
      "source": [
        "trainSet=np.arange(200*5600).reshape(200,5600)\n",
        "testSet=np.arange(200*5600).reshape(200,5600)\n",
        "trainLabel=[]\n",
        "testLabel=[]\n",
        "j,k=0,0\n",
        "for i in range(0,400):\n",
        "    if(i%2==0):\n",
        "        testSet[j]=dataMatrix[i]\n",
        "        testLabel.append(label[i])\n",
        "        j+=1\n",
        "    else:\n",
        "        trainSet[k]=dataMatrix[i]\n",
        "        trainLabel.append(label[i])\n",
        "        k+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5-MJydgRlHo"
      },
      "source": [
        "def NaiveBayes(Data,Labels):\n",
        "    Instances = Data.shape[0]\n",
        "    Features = Data.shape[1]\n",
        "    DataClasses = {}\n",
        "    for i in range(Instances):\n",
        "        if(Labels[i] not in DataClasses):\n",
        "            DataClasses[Labels[i]] = np.array([Data[i]])\n",
        "        else:\n",
        "            DataClasses[Labels[i]] = np.concatenate([DataClasses[Labels[i]],[Data[i]]])\n",
        "\n",
        "    NumberOfClasses = len(DataClasses)\n",
        "    Size = np.zeros(NumberOfClasses)\n",
        "    Prior = np.zeros(NumberOfClasses)\n",
        "    Mean = np.zeros((NumberOfClasses,Features))\n",
        "    Variance = np.zeros((NumberOfClasses,Features))\n",
        "    for i in range(1,NumberOfClasses+1):\n",
        "        Size[i-1] = DataClasses[i].shape[0]\n",
        "        Prior[i-1] = Size[i-1]/Instances\n",
        "        Mean[i-1] = np.mean(DataClasses[i], axis=0)\n",
        "        Variance[i-1] = np.var(DataClasses[i], axis=0)        \n",
        "\n",
        "    return Prior,Mean,Variance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHz3042_TFEp"
      },
      "source": [
        "def NaiveBayesClassifier(X,Mean,Variance):\n",
        "    if(Variance == 0): return 1.0\n",
        "    Exponent = math.exp(-(math.pow(X-Mean,2)))\n",
        "    return (1 / (math.sqrt(2.0*math.pi)))*(Exponent)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i72Og4mXT_F6"
      },
      "source": [
        "def Predict(Test,Prior,Mean,Variance):\n",
        "    NumberOfClasses = Mean.shape[0]\n",
        "    NumberOfFeatures = Mean.shape[1]\n",
        "    Posterior = np.zeros(NumberOfClasses)\n",
        "    Epsilon = 0.0001\n",
        "    Likelihood = 0\n",
        "    for i in range(NumberOfClasses):\n",
        "        Likelihood = 0\n",
        "        for j in range(NumberOfFeatures):\n",
        "            Probabiltiy = NaiveBayesClassifier(Test[j],Mean[i,j],Variance=[i,j])+Epsilon\n",
        "            Likelihood += np.log(Probabiltiy)\n",
        "        Posterior[i] = Likelihood + np.log(Prior[i])\n",
        "    \n",
        "    return np.argmax(Posterior)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxE-KDlpQgn1"
      },
      "source": [
        "Prior,Mean,Variance = NaiveBayes(trainSet,trainLabel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0Eu40ZaVZ4u"
      },
      "source": [
        "Predictions = np.zeros(testSet.shape[0])\n",
        "for i in range(testSet.shape[0]):\n",
        "    Predictions[i] = Predict(testSet[i],Prior,Mean,Variance)+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpwJDTh0QmMH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cb3d678-087a-4bd4-ce6a-765bd55a65b5"
      },
      "source": [
        "accuracy_score(testLabel,Predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.805"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3Aa9iqsaagU",
        "outputId": "51e3ceed-c8dc-4ed9-8ba4-4d56d265e992"
      },
      "source": [
        "np.set_printoptions(threshold=np.inf)\n",
        "print(confusion_matrix(testLabel,Predictions))\n",
        "np.set_printoptions()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 2 0 0]\n",
            " [0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 2 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 4 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
            "  0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 3 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0\n",
            "  1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 4 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 2 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  5 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 5 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 3 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  1 0 0 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzUn9p7wa5bN"
      },
      "source": [
        "trainMean=np.mean(trainSet,axis=0)\n",
        "centeredTrainMatrix=trainSet-trainMean\n",
        "covMatrix = (1/200)*np.dot(np.transpose(centeredTrainMatrix), centeredTrainMatrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4ZhJPYNbBQS"
      },
      "source": [
        "eigVal,eigVect=np.linalg.eigh(covMatrix)\n",
        "eigVal=np.flip(eigVal,axis=0)\n",
        "eigVect=np.flip(eigVect,axis=1)\n",
        "UsedeigVal=eigVal[0:40]\n",
        "UsedeigVect=eigVect[:,0:40]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVe17mSKbzIw"
      },
      "source": [
        "reducedTrain1= np.dot(trainSet,UsedeigVect)\n",
        "reducedTest1= np.dot(testSet,UsedeigVect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do_wpLegcAtH"
      },
      "source": [
        "Prior1,Mean1,Variance1 = NaiveBayes(reducedTrain1,trainLabel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba8TZr4dcLJq"
      },
      "source": [
        "Predictions1 = np.zeros(testSet.shape[0])\n",
        "for i in range(testSet.shape[0]):\n",
        "    Predictions1[i] = Predict(reducedTest1[i],Prior1,Mean1,Variance1)+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuD0yRNrcXMZ",
        "outputId": "611e20e5-8068-4205-bacf-4932de5da93a"
      },
      "source": [
        "accuracy_score(testLabel,Predictions1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.065"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY3ujWMYcjUd",
        "outputId": "8925309b-8bc5-421b-9cb6-e43f93a7be88"
      },
      "source": [
        "np.set_printoptions(threshold=np.inf)\n",
        "print(confusion_matrix(testLabel,Predictions1))\n",
        "np.set_printoptions()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
            "  1 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 1 0 0]\n",
            " [0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 1]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  1 0 1 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            "  0 1 0 0]\n",
            " [0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
            "  0 0 1 0]\n",
            " [0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
            "  0 0 0 1]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            "  0 0 0 2]\n",
            " [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
            "  0 0 1 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 2]\n",
            " [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 1]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
            "  0 0 0 1]\n",
            " [0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 2 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [2 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
            "  1 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
            "  0 0 0 1]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 1]\n",
            " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
            "  1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 1]\n",
            " [0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  1 1 0 0]\n",
            " [0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0\n",
            "  0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
            "  0 2 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrficePwc5Ae"
      },
      "source": [
        "Data = np.array([[2,6],[3,3],[3,5],[4,3],[4,4],[4,5],\n",
        "                        [5,3],[5,5],[6,2],[6,4],[6,6],[7,2],[7,3],[7,4],[7,5],\n",
        "                        [8,4],[9,2],[9,3],[10,1],[10,3],[10,5],\n",
        "                        [11,3],[11,4],[12,2],[13,5]])\n",
        "Labels = np.array([1,2,1,2,1,2,1,2,1,1,1,3,2,2,2,1,1,1,3,3,3,3,3,3,3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JawMxYfwc7v6"
      },
      "source": [
        "Prior2,Mean2,Variance2 = NaiveBayes(Data,Labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo7KX84pdGqi",
        "outputId": "622535cc-2f0a-42dc-fc4a-775f19c22be3"
      },
      "source": [
        "print(\"Prior probability of Class1 = {0}\\nPrior probability of Class2 = {1}\\nPrior probability of Class3 = {2}\".format(Prior2[0],Prior2[1],Prior2[2]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prior probability of Class1 = 0.4\n",
            "Prior probability of Class2 = 0.28\n",
            "Prior probability of Class3 = 0.32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wbgpLsWdL1j",
        "outputId": "1a3c7d16-24d2-4e16-a4b1-d103f750f6a3"
      },
      "source": [
        "print(\"Mean of Class1 = {0}\\nMean of Class2 = {1}\\nMean of Class3 = {2}\".format(Mean2[0],Mean2[1],Mean2[2]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of Class1 = [5.8 3.9]\n",
            "Mean of Class2 = [5.28571429 4.        ]\n",
            "Mean of Class3 = [10.5    3.125]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L__jzZPdfYY",
        "outputId": "db8b6865-4647-4b95-8ded-d0860e793113"
      },
      "source": [
        "print(\"Variance of Class1 = {0}\\nVariance of Class2 = {1}\\nVariance of Class3 = {2}\".format(Variance2[0],Variance2[1],Variance2[2]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Variance of Class1 = [5.16 1.89]\n",
            "Variance of Class2 = [2.48979592 0.85714286]\n",
            "Variance of Class3 = [2.75     1.859375]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXX43nCXdxt7",
        "outputId": "55c27a3f-b1dd-4d89-a373-0dc7ae90f363"
      },
      "source": [
        "print(\"Point (6,5) is Class\",Predict([6,5],Prior2,Mean2,Variance2)+1)\n",
        "print(\"Point (9,4) is Class\",Predict([9,4],Prior2,Mean2,Variance2)+1)\n",
        "print(\"Point (8,5) is Class\",Predict([8,5],Prior2,Mean2,Variance2)+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Point (6,5) is Class 1\n",
            "Point (9,4) is Class 3\n",
            "Point (8,5) is Class 1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}